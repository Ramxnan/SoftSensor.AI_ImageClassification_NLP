{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ramanan\n",
    "### ramanan.palur@gmail.com\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task(WSI) Medical image related\n",
    "Digital pathology has emerged with the digitization of patient tissue samples and in particular\n",
    "the use of digital whole slide images (WSIs). Image analysis of WSIs (Whole Slide Images),\n",
    "promises to play an important role in helping the pathologists by indicating potential disease\n",
    "locations and by aiding their interpretation.\n",
    "These images are very large therefore problem arises in analysing them as a whole. So\n",
    "sometimes they are used as a whole or sometimes they are divided into tiles. However, they\n",
    "cannot be analysed properly further if any pen marks are present on it. Also only the tissue\n",
    "region in the slide is important. To analyse the fine details, various filters and masks are applied\n",
    "on it.\n",
    "Stain color from one laboratory differs from other. Even though they might be of same organ,\n",
    "same tissue of two images might appear different. Segmentation is used in these images to\n",
    "localize the object. However, due to very less variations in the images visually, it becomes\n",
    "difficult to classify objects and localize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installtion of dependencies and setting path for openslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openslide-python\n",
    "# %pip install matplotlib\n",
    "#OPENSLIDE_PATH = r\"C:/Users/raman/anaconda3/Lib/site-packages/openslide/openslide-win64-20171122/bin\"\n",
    "\n",
    "#import os\n",
    "# os.environ['PATH'] = \"C:\\\\Users\\\\raman\\\\anaconda3\\\\Lib\\\\site-packages\\\\openslide\\\\openslide-win64-20171122\\\\bin\" + \";\" + os.environ['PATH']\n",
    "# if hasattr(os, 'add_dll_directory'):\n",
    "#      with os.add_dll_directory(OPENSLIDE_PATH):\n",
    "#          import openslide\n",
    "# else:\n",
    "#      import openslide\n",
    "from openslide import open_slide # pip install openslide-python\n",
    "import openslide # pip install openslide-python\n",
    "from PIL import Image # pip install pillow\n",
    "import numpy as np # pip install numpy\n",
    "import matplotlib.pyplot as plt # pip install matplotlib\n",
    "from openslide.deepzoom import DeepZoomGenerator # pip install openslide-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the slide of normal and reactive lymph and save it as tiles of size 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_normal = open_slide(\"E:\\\\Projects\\\\Sensorskill\\\\Normal Lymphnode.svs\") # Open the slide\n",
    "tiles_normal= DeepZoomGenerator(slide_normal, tile_size=256, overlap=0, limit_bounds=False) # Create a DeepZoomGenerator object\n",
    "cols, rows = tiles_normal.level_tiles[-1] # Get the number of tiles in the last level\n",
    "print(\"Number of columns in the tiles object are: \", cols) # Print the number of columns\n",
    "print(\"Number of rows in the tiles object are: \", rows) # Print the number of rows\n",
    "tile_dir = \"E:\\\\Projects\\\\Sensorskill\\DL\\\\Normal_Tiles_Tif\\\\Original\" # Set the directory to save the tiles\n",
    "for row in range(rows): # Loop through the rows\n",
    "    for col in range(cols): # Loop through the columns \n",
    "        tile_name = os.path.join(tile_dir, '%d_%d' % (col, row)+'_Normal') # Create the tile name\n",
    "        print(\"Now saving tile with title: \", tile_name) # Print the tile name\n",
    "        temp_tile = tiles_normal.get_tile(16, (col, row)) # Get the tile\n",
    "        temp_tile_RGB = temp_tile.convert('RGB') # Convert the tile to RGB\n",
    "        temp_tile_np = np.array(temp_tile_RGB) # Convert the tile to a numpy array\n",
    "        temp_tile_PIL = Image.fromarray(temp_tile_np) # Convert the numpy array to a PIL image\n",
    "        temp_tile_PIL.save(tile_name + \".tif\") # Save the tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_reactive = open_slide(\"E:\\\\Projects\\\\Sensorskill\\\\Reactive hyperplasia.svs\") # Open the slide\n",
    "tiles_reactive= DeepZoomGenerator(slide_reactive, tile_size=256, overlap=0, limit_bounds=False) # Create a DeepZoomGenerator object\n",
    "cols, rows = tiles_reactive.level_tiles[-1] # Get the number of tiles in the last level\n",
    "print(\"Number of columns in the tiles object are: \", cols) # Print the number of columns\n",
    "print(\"Number of rows in the tiles object are: \", rows) # Print the number of rows \n",
    "tile_dir = \"E:\\\\Projects\\\\Sensorskill\\\\DL\\\\Reactive_tiles_Tif\\\\Original\" # Set the directory to save the tiles\n",
    "for row in range(rows): # Loop through the rows\n",
    "    for col in range(cols): # Loop through the columns \n",
    "        tile_name = os.path.join(tile_dir, '%d_%d' % (col, row)+'_Reactive') # Create the tile name\n",
    "        print(\"Now saving tile with title: \", tile_name) # Print the tile name\n",
    "        temp_tile = tiles_reactive.get_tile(15, (col, row)) # Get the tile\n",
    "        temp_tile_RGB = temp_tile.convert('RGB') # Convert the tile to RGB\n",
    "        temp_tile_np = np.array(temp_tile_RGB) # Convert the tile to a numpy array\n",
    "        temp_tile_PIL = Image.fromarray(temp_tile_np) # Convert the numpy array to a PIL image\n",
    "        temp_tile_PIL.save(tile_name + \".tif\") # Save the tile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out the good tiles and save it as tiles of size 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image   # pip install pillow\n",
    "import numpy as np # pip install numpy\n",
    "from matplotlib import pyplot as plt # pip install matplotlib\n",
    "import tifffile as tiff  # pip install tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_std_pixel_value(image): # Function to find the mean and standard deviation of the pixel values\n",
    "    avg = image.mean()  # Find the mean of the image\n",
    "    std = image.std() # Find the standard deviation of the image\n",
    "    avg_pixel_value=avg # Set the average pixel value to the average\n",
    "    std_pixel_value=std # Set the standard deviation pixel value to the standard deviation\n",
    "\n",
    "    return(avg_pixel_value, stddev_pixel_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Import the os module\n",
    "orig_tile_dir_name = \"E:\\\\Projects\\\\Sensorskill\\\\DL\\\\Normal_Tiles_Tif\\\\Original\" # Set the directory to load the tiles\n",
    "savings_dir_name = \"E:\\\\Projects\\\\Sensorskill\\\\DL\\\\Normal_Tiles_Tif\\\\Good\" # Set the directory to save the tiles\n",
    "for file in os.listdir(orig_tile_dir_name): # Loop through the files in the directory\n",
    "    if file.endswith(\".tif\"): # Check if the file is a tif file\n",
    "        image = tiff.imread(orig_tile_dir_name+\"\\\\\"+file) # Load the image\n",
    "        avg_pixel_value, stddev_pixel_value = find_mean_std_pixel_value(image) # Find the mean and standard deviation of the pixel values\n",
    "        if stddev_pixel_value > 15 and avg_pixel_value <230 and image.shape[0]==256 and image.shape[1]==256: # Check if the standard deviation is greater than 15 and the average pixel value is less than 230 and the image is 256x256\n",
    "            path=savings_dir_name+\"\\\\\"+file.split(\".\")[0]+\".tif\" # Create the path to save the image\n",
    "            tiff.imsave(path, image) # Save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Import the os module \n",
    "orig_tile_dir_name = \"E:\\\\Projects\\\\Sensorskill\\\\DL\\\\Reactive_Tiles_Tif\\\\Original\" # Set the directory to load the tiles\n",
    "savings_dir_name = \"E:\\\\Projects\\\\Sensorskill\\\\DL\\\\Reactive_Tiles_Tif\\\\Good\" # Set the directory to save the tiles\n",
    "for file in os.listdir(orig_tile_dir_name): # Loop through the files in the directory\n",
    "    if file.endswith(\".tif\"): # Check if the file is a tif file\n",
    "        image = tiff.imread(orig_tile_dir_name+\"\\\\\"+file) # Load the image\n",
    "        avg_pixel_value, stddev_pixel_value = find_mean_std_pixel_value(image) # Find the mean and standard deviation of the pixel values\n",
    "        if stddev_pixel_value > 15 and avg_pixel_value <230 and image.shape[0] == 256 and image.shape[1] == 256: # Check if the standard deviation is greater than 15 and the average pixel value is less than 230 and the image is 256x256\n",
    "            path=savings_dir_name+\"\\\\\"+file.split(\".\")[0]+\".tif\" # Create the path to save the image\n",
    "            tiff.imsave(path, image) # Save the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of the Goods tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # pip install numpy\n",
    "import cv2 # pip install opencv-python\n",
    "from matplotlib import pyplot as plt # pip install matplotlib\n",
    "def norm_HnE(img, Io=240, alpha=1, beta=0.15): # Function to normalize the HnE image\n",
    "    ######## Step 1: Convert RGB to OD ###################\n",
    "    #Read the above referenced papers on this topic. \n",
    "    HERef = np.array([[0.5626, 0.2159],\n",
    "                      [0.7201, 0.8012],\n",
    "                      [0.4062, 0.5581]])\n",
    "    ### reference maximum stain concentrations for H&E\n",
    "    maxCRef = np.array([1.9705, 1.0308])\n",
    "    \n",
    "    \n",
    "    # extract the height, width and num of channels of image\n",
    "    h, w, c = img.shape\n",
    "    \n",
    "    # reshape image to multiple rows and 3 columns.\n",
    "    #Num of rows depends on the image size (wxh)\n",
    "    img = img.reshape((-1,3))\n",
    "    \n",
    "    # calculate optical density\n",
    "    # OD = −log10(I)  \n",
    "    #OD = -np.log10(img+0.004)  #Use this when reading images with skimage\n",
    "    #Adding 0.004 just to avoid log of zero. \n",
    "    \n",
    "    OD = -np.log10((img.astype(np.float)+1)/Io) #Use this for opencv imread\n",
    "    #Add 1 in case any pixels in the image have a value of 0 (log 0 is indeterminate)\n",
    "    \n",
    "    \n",
    "    ############ Step 2: Remove data with OD intensity less than β ############\n",
    "    # remove transparent pixels (clear region with no tissue)\n",
    "    ODhat = OD[~np.any(OD < beta, axis=1)] #Returns an array where OD values are above beta\n",
    "    #Check by printing ODhat.min()\n",
    "    \n",
    "    ############# Step 3: Calculate SVD on the OD tuples ######################\n",
    "    #Estimate covariance matrix of ODhat (transposed)\n",
    "    # and then compute eigen values & eigenvectors.\n",
    "    eigvals, eigvecs = np.linalg.eigh(np.cov(ODhat.T))\n",
    "    \n",
    "    \n",
    "    ######## Step 4: Create plane from the SVD directions with two largest values ######\n",
    "    #project on the plane spanned by the eigenvectors corresponding to the two \n",
    "    # largest eigenvalues    \n",
    "    That = ODhat.dot(eigvecs[:,1:3]) #Dot product\n",
    "    \n",
    "    ############### Step 5: Project data onto the plane, and normalize to unit length ###########\n",
    "    ############## Step 6: Calculate angle of each point wrt the first SVD direction ########\n",
    "    #find the min and max vectors and project back to OD space\n",
    "    phi = np.arctan2(That[:,1],That[:,0])\n",
    "    \n",
    "    minPhi = np.percentile(phi, alpha)\n",
    "    maxPhi = np.percentile(phi, 100-alpha)\n",
    "    \n",
    "    vMin = eigvecs[:,1:3].dot(np.array([(np.cos(minPhi), np.sin(minPhi))]).T)\n",
    "    vMax = eigvecs[:,1:3].dot(np.array([(np.cos(maxPhi), np.sin(maxPhi))]).T)\n",
    "    \n",
    "    \n",
    "    # a heuristic to make the vector corresponding to hematoxylin first and the \n",
    "    # one corresponding to eosin second\n",
    "    if vMin[0] > vMax[0]:    \n",
    "        HE = np.array((vMin[:,0], vMax[:,0])).T\n",
    "        \n",
    "    else:\n",
    "        HE = np.array((vMax[:,0], vMin[:,0])).T\n",
    "    \n",
    "    \n",
    "    # rows correspond to channels (RGB), columns to OD values\n",
    "    Y = np.reshape(OD, (-1, 3)).T\n",
    "    \n",
    "    # determine concentrations of the individual stains\n",
    "    C = np.linalg.lstsq(HE,Y, rcond=None)[0]\n",
    "    \n",
    "    # normalize stain concentrations\n",
    "    maxC = np.array([np.percentile(C[0,:], 99), np.percentile(C[1,:],99)])\n",
    "    tmp = np.divide(maxC,maxCRef)\n",
    "    C2 = np.divide(C,tmp[:, np.newaxis])\n",
    "    \n",
    "    ###### Step 8: Convert extreme values back to OD space\n",
    "    # recreate the normalized image using reference mixing matrix \n",
    "    \n",
    "    Inorm = np.multiply(Io, np.exp(-HERef.dot(C2)))\n",
    "    Inorm[Inorm>255] = 254\n",
    "    Inorm = np.reshape(Inorm.T, (h, w, 3)).astype(np.uint8)  \n",
    "    \n",
    "    # Separating H and E components\n",
    "    \n",
    "    H = np.multiply(Io, np.exp(np.expand_dims(-HERef[:,0], axis=1).dot(np.expand_dims(C2[0,:], axis=0))))\n",
    "    H[H>255] = 254\n",
    "    H = np.reshape(H.T, (h, w, 3)).astype(np.uint8)\n",
    "    \n",
    "    E = np.multiply(Io, np.exp(np.expand_dims(-HERef[:,1], axis=1).dot(np.expand_dims(C2[1,:], axis=0))))\n",
    "    E[E>255] = 254\n",
    "    E = np.reshape(E.T, (h, w, 3)).astype(np.uint8)\n",
    "    \n",
    "    return (Inorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # pip install pillow\n",
    "import numpy as np # pip install numpy\n",
    "from matplotlib import pyplot as plt # pip install matplotlib\n",
    "import tifffile as tiff # pip install tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # pip install os\n",
    "normal_good_path=\"E:\\\\Projects\\\\Sensorskill\\\\DL\\\\Normal_Tiles_Tif\\\\Good\" # Path to the good normal tiles\n",
    "saving_dir=\"E:\\\\Projects\\\\Sensorskill\\\\DL\\\\Normal_Tiles_Tif\\\\Normalized\" # Directory to save the normalized images\n",
    "for filename in os.listdir(normal_good_path): # Loop through the files in the directory\n",
    "    if filename.endswith(\".tif\"): # Check if the file is a tif file\n",
    "        img=tiff.imread(normal_good_path+\"\\\\\"+filename) # Read the image\n",
    "        try: # Try to normalize the image\n",
    "            Inorm=norm_HnE(img) # Normalize the image\n",
    "            tiff.imsave(saving_dir+\"\\\\\"+filename, Inorm) # Save the image\n",
    "        except: # If the image is not normalized, print an error message\n",
    "            print(\"Error in \"+filename) # Print the error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # pip install os\n",
    "normal_good_path=\"E:\\\\Projects\\\\Sensorskill\\\\DL\\\\Reactive_Tiles_Tif\\\\Good\" # Path to the good reactive tiles\n",
    "saving_dir=\"E:\\\\Projects\\\\Sensorskill\\\\DL\\\\Reactive_Tiles_Tif\\\\Normalized\" # Directory to save the normalized images\n",
    "for filename in os.listdir(normal_good_path): # Loop through the files in the directory\n",
    "    if filename.endswith(\".tif\"): # Check if the file is a tif file\n",
    "        img=tiff.imread(normal_good_path+\"\\\\\"+filename) # Read the image\n",
    "        try: # Try to normalize the image\n",
    "            Inorm=norm_HnE(img) # Normalize the image\n",
    "            tiff.imsave(saving_dir+\"\\\\\"+filename, Inorm) # Save the image\n",
    "        except: # If the image is not normalized, print an error message\n",
    "            print(\"Error in \"+filename) # Print the error message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raman\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\raman\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\raman\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt     # pip install matplotlib\n",
    "import matplotlib.image as mpimg # pip install matplotlib\n",
    "from tqdm import tqdm # pip install tqdm\n",
    "\n",
    "plt.style.use('classic') # Set the style to classic \n",
    "#############################################################\n",
    "from keras.preprocessing.image import ImageDataGenerator # pip install keras\n",
    "from keras.models import Sequential # pip install keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization # pip install keras\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense # pip install keras\n",
    "#from keras import backend as K\n",
    "####################################################\n",
    "import os # pip install os\n",
    "import cv2 # pip install opencv-python\n",
    "from PIL import Image # pip install pillow \n",
    "import numpy as np # pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = \"E:\\\\Projects\\\\Sensorskill\\\\DL\"   # Path to the directory containing the images\n",
    "dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  \n",
    "label = []  #Place holders to define add labels. 0 is for normal Lymph nodes, 1 is for reactive Lymph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 1406.14it/s]\n"
     ]
    }
   ],
   "source": [
    "Lymph_images = os.listdir(image_directory + '\\\\Normal_Tiles_Tif\\\\Normalizedv2') # List of all the images in the directory\n",
    "for i, image_name in tqdm(enumerate(Lymph_images)): # Loop through the images\n",
    "    if image_name.endswith(\".tif\"): # Check if the image is a tif file\n",
    "        image = cv2.imread(image_directory + '\\\\Normal_Tiles_Tif\\\\Normalizedv2\\\\' + image_name) # Read the image\n",
    "        image = Image.fromarray(image, 'RGB') # Convert the image to RGB\n",
    "        dataset.append(np.array(image)) # Append the image to the dataset\n",
    "        label.append(0)  # Append the label to the label\n",
    "        #0 means normal Lymph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 1327.72it/s]\n"
     ]
    }
   ],
   "source": [
    "Reactive_images = os.listdir(image_directory + '\\\\Reactive_tiles_Tif\\\\Normalizedv2') # List of all the images in the directory\n",
    "for i, image_name in tqdm(enumerate(Reactive_images)): # Loop through the images\n",
    "    if image_name.endswith(\".tif\"): # Check if the image is a tif file\n",
    "        image = cv2.imread(image_directory + '\\\\Reactive_tiles_Tif\\\\Normalizedv2\\\\' + image_name) # Read the image\n",
    "        image = Image.fromarray(image, 'RGB') # Convert the image to RGB\n",
    "        dataset.append(np.array(image)) # Append the image to the dataset\n",
    "        label.append(1) # Append the label to the label\n",
    "        #1 means reactive Lymph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset) # Convert the dataset to a numpy array\n",
    "label = np.array(label) # Convert the label to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # pip install sklearn\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0) # Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize # pip install keras\n",
    "X_train = normalize(X_train, axis=1) # Normalize the training data\n",
    "X_test = normalize(X_test, axis=1) # Normalize the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_shape = (256,256,3) # Shape of the input data\n",
    "\n",
    "model = Sequential() # Create a sequential model\n",
    "model.add(Conv2D(32, (3, 3), input_shape=Input_shape)) # Add a convolutional layer with 32 filters and a 3x3 kernel\n",
    "model.add(Activation('relu')) # Add an activation function\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # Add a max pooling layer with a 2x2 pool size\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer = 'he_uniform')) # Add a convolutional layer with 32 filters and a 3x3 kernel\n",
    "model.add(Activation('relu')) # Add an activation function\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # Add a max pooling layer with a 2x2 pool size\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer = 'he_uniform')) # Add a convolutional layer with 64 filters and a 3x3 kernel\n",
    "model.add(Activation('relu')) # Add an activation function\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # Add a max pooling layer with a 2x2 pool size\n",
    "\n",
    "model.add(Flatten()) # Flatten the data for the dense layers\n",
    "model.add(Dense(64)) # Add a dense layer with 64 neurons\n",
    "model.add(Activation('relu')) # Add an activation function\n",
    "model.add(Dropout(0.5)) # Add a dropout layer with a dropout rate of 0.5\n",
    " \n",
    "model.add(Dense(1)) # Add a dense layer with 1 neuron\n",
    "model.add(Activation('sigmoid'))   # Add an activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 254, 254, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 125, 125, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 60, 60, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                3686464   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,715,169\n",
      "Trainable params: 3,715,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', # Compile the model with a loss function of binary crossentropy\n",
    "              optimizer='rmsprop',            #  Use the rmsprop optimizer or any other optimizer like adam on a trial and error basis\n",
    "              metrics=['accuracy']) # Use the accuracy metric to evaluate the model\n",
    "\n",
    "print(model.summary())     # Print the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 13s 871ms/step - loss: 1.4621 - accuracy: 0.5000 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad' defined at (most recent call last):\n    File \"c:\\Users\\raman\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\raman\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_276\\648249006.py\", line 1, in <cell line: 1>\n      history = model.fit(X_train[:200],  # Train the model on the training data\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad'\nOOM when allocating tensor with shape[64,32,254,254] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1183]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32me:\\Projects\\Sensorskill\\FInal.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Projects/Sensorskill/FInal.ipynb#ch0000020?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train[:\u001b[39m200\u001b[39;49m],  \u001b[39m# Train the model on the training data\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Sensorskill/FInal.ipynb#ch0000020?line=1'>2</a>\u001b[0m                          y_train[:\u001b[39m200\u001b[39;49m],  \u001b[39m# with the labels\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Sensorskill/FInal.ipynb#ch0000020?line=2'>3</a>\u001b[0m                          batch_size \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m,  \u001b[39m# Use a batch size of 64\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Sensorskill/FInal.ipynb#ch0000020?line=3'>4</a>\u001b[0m                          verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,  \u001b[39m# Show a progress bar\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Sensorskill/FInal.ipynb#ch0000020?line=4'>5</a>\u001b[0m                          epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m,       \u001b[39m# Train the model for 10 epochs \u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Sensorskill/FInal.ipynb#ch0000020?line=5'>6</a>\u001b[0m                          validation_data\u001b[39m=\u001b[39;49m(X_test,y_test), \u001b[39m# Use the testing data for validation\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Sensorskill/FInal.ipynb#ch0000020?line=6'>7</a>\u001b[0m                          shuffle \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m \u001b[39m# Shuffle the data\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Projects/Sensorskill/FInal.ipynb#ch0000020?line=7'>8</a>\u001b[0m                      )\n",
      "File \u001b[1;32mc:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\raman\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad' defined at (most recent call last):\n    File \"c:\\Users\\raman\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\raman\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\raman\\AppData\\Local\\Temp\\ipykernel_276\\648249006.py\", line 1, in <cell line: 1>\n      history = model.fit(X_train[:200],  # Train the model on the training data\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"c:\\Users\\raman\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad'\nOOM when allocating tensor with shape[64,32,254,254] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1183]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train[:200],  # Train the model on the training data\n",
    "                         y_train[:200],  # with the labels\n",
    "                         batch_size = 8,  # Use a batch size of 64\n",
    "                         verbose = 1,  # Show a progress bar\n",
    "                         epochs = 10,       # Train the model for 10 epochs \n",
    "                         validation_data=(X_test,y_test), # Use the testing data for validation\n",
    "                         shuffle = False # Shuffle the data\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the images are very large, it is difficult to analyse them as a whole. So, they are\n",
    "divided into tiles of size 256x256. These tiles are then filtered out to remove the bad tiles.\n",
    "The good tiles are then normalized and the model is built.\n",
    "\n",
    "The dataset after Normalization has a size of 15GB.\n",
    "\n",
    "Due to the large size of the dataset, it is difficult to train the model where I ran into Resource Exceeded error from the second epoch.\n",
    "\n",
    "After taking only 200 images from 15000, the model is trained for 1 epoch before running to the above mentioned error.\n",
    "\n",
    "After one epoch, an accuracy of 0.5 is achieved which is good considering:\n",
    "1. only 200 images are used for training out of 15000 images\n",
    "2. the model trained for only one epoch\n",
    "3. the batch size is reduced to 8 from 64 to run the model atleast once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f809bf94e29cee2d7935c4f29b9a3ae08e0707af3b5b65c6833e6a437508cc17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
