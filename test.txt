Lab Activity 1 - Grouping the activities by their Names and Count.

val static = spark.read.json("activity1.json")
val dataschema = static.schema
val streaming = spark.readStream.schema(dataschema).option("maxFilesPerTrigger",1).json("dataPractice")
val activitycounts = streaming.groupBy("gt").count()
val activityquery = activitycounts.writeStream.queryName("activity_counts").format("console").outputMode("complete").start()


Lab Activity 2 - Write a Streaming Application that groups the streaming data by Gender and Calculate Average weight and height.

val static = spark.read.format("csv").option("header","true").load("weight-heightaa.csv")
val dataschema = static.schema
val streaming = spark.readStream.schema(dataschema).option("maxFilesPerTrigger",1).option("header","true").csv("dataOuput2")
val activitycounts = streaming.groupBy("Gender").agg(avg("Height"),avg("Weight"))
val activityquery = activitycounts.writeStream.queryName("activity_avg_count").format("console").outputMode("complete").start()



Lab Activity 3 - that reads the data through a TCP Socket and perform word count.

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.{explode, split}
val df = spark.readStream.format("socket").option("host","localhost").option("port","9090").load()
val wordsDF = df.select(explode(split(df("value")," ")).alias("word"))
val count = wordsDF.groupBy("word").count()
val query = count.writeStream.queryName("tcpdemo2").format("console").outputMode("complete").start()



Lab Activity 4 - Group by their Names and Count the Number of Occcurences with MaxFilesPerTriggers as 2

val static = spark.read.json("activity1.json")
val dataschema = static.schema
val streaming = spark.readStream.schema(dataschema).option("maxFilesPerTrigger",2).json("PracticeOutput")
val activitycounts = streaming.groupBy("gt").count()
val activityquery = activitycounts.writeStream.queryName("activity_counts").format("console").outputMode("complete").start()



Lab Activity 5 - using Trigger Processing Time to Process One file every one minute.

val static = spark.read.json("activity1.json")
val dataschema = static.schema
val streaming = spark.readStream.schema(dataschema).option("maxFilesPerTrigger",1).json("PracticeOutput")
val activitycounts = streaming.groupBy("gt").count()
val activityquery = activitycounts.writeStream.trigger(Trigger.ProcessingTime("1 minute").queryName("activity_counts").format("console").outputMode("complete").start()



Lab Activity 6 - Format - Memory 

val static = spark.read.json("activity1.json")
val dataschema = static.schema
val streaming = spark.readStream.schema(dataschema).option("maxFilesPerTrigger",1).json("Today")
val activitycounts = streaming.groupBy("gt").count()
val activityquery = activitycounts.writeStream.queryName("activity_counts1").format("memory").outputMode("complete").start()
spark sql("SELECT * FROM activity_counts").show()